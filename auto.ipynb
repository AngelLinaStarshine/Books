{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AngelLinaStarshine/Books/blob/master/auto.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDn_lVxg3Z2G"
      },
      "source": [
        "# Importing a library that is not in Colaboratory\n",
        "\n",
        "To import a library that's not in Colaboratory by default, you can use `!pip install` or `!apt-get install`."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "\n",
        "#https://stackoverflow.com/questions/64491693/keyerror-none-of-are-in-the-columns-when-using-the-python-pandas-set-index\n",
        "#https://www.gnu.org/software/wget/\n",
        "#https://automaticaddison.com/predict-vehicle-fuel-economy-using-a-deep-neural-network/\n",
        "#https://www.tensorflow.org/tutorials/keras/regression\n",
        "#https://thecleverprogrammer.com/2020/09/02/predict-fuel-efficiency-with-machine-learning/\n",
        "\n",
        "\n",
        "column_names = ['mpg', 'cylinders', 'displacement', 'horsepower', 'weight', 'acceleration', 'model_year', 'origin', 'car_name']\n",
        "\n",
        "auto_mpg_df = pd.read_csv('auto-mpg.data', delim_whitespace=True, names=column_names, na_values='?')\n",
        "\n",
        "auto_mpg_df.drop(columns=['car_name', 'origin'], inplace=True)\n",
        "\n",
        "auto_mpg_df['horsepower'] = auto_mpg_df.groupby('cylinders')['horsepower'].transform(lambda x: x.fillna(x.mean()))\n",
        "\n",
        "auto_mpg_df['model_year'] = auto_mpg_df['model_year'].apply(lambda x: x + 2000 if x < 25 else x + 1900)\n",
        "\n",
        "X = auto_mpg_df.drop('mpg', axis=1)\n",
        "y = auto_mpg_df['mpg']\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.5)\n",
        "\n",
        "#https://stackoverflow.com/questions/73390492/what-is-the-correct-code-to-use-standardscaler-on-x-train-and-x-test-in-sklear\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_val_scaled = scaler.transform(X_val)\n",
        "\n",
        "#https://stackoverflow.com/questions/44747343/keras-input-explanation-input-shape-units-batch-size-dim-etc\n",
        "#https://keras.io/guides/sequential_model/\n",
        "\n",
        "model = Sequential([\n",
        "    Input(shape=(X_train_scaled.shape[1],)),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "#https://stackoverflow.com/questions/51256695/loss-metrics-and-scoring-in-keras\n",
        "\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "history = model.fit(X_train_scaled, y_train, epochs=10, validation_data=(X_val_scaled, y_val))\n",
        "\n",
        "#https://www.geeksforgeeks.org/analyzing-selling-price-of-used-cars-using-python/\n",
        "\n",
        "new_vehicles = pd.DataFrame({\n",
        "    'cylinders': [6, 12, 8, 8, 4, 6, 3, 3, 4, 4],\n",
        "    'displacement': [2170, 6498, 3902, 6162, 122, 3232, 598, 900, 1189, 201],\n",
        "    'horsepower': [502, 730, 986, 670, 181, 155, 89, 50, 60, 40],\n",
        "    'weight': [3164, 3472, 3020, 3721, 2496, 3232, 1550, 642, 2355, 2265],\n",
        "    'acceleration': [4.2, 3.2, 2.5, 2.6, 8.3, 11.5, 10.1, 5.8, 28.1, 32],\n",
        "    'model_year': [2025, 2025, 2025, 2025, 2025, 1969, 2025, 2025, 1964, 1908]\n",
        "})\n",
        "\n",
        "#https://stackoverflow.com/questions/38780302/predicting-new-data-using-sklearn-after-standardizing-the-training-data\n",
        "\n",
        "new_vehicles_scaled = scaler.transform(new_vehicles)\n",
        "\n",
        "predicted_mpg = model.predict(new_vehicles_scaled)\n",
        "\n",
        "val_loss = model.evaluate(X_val_scaled, y_val)\n",
        "\n",
        "print(f\"Val loss: {val_loss}\")\n",
        "print(predicted_mpg)"
      ],
      "metadata": {
        "id": "PRDSckJ0ooQh",
        "outputId": "2d24e157-52fe-44b6-869a-133a554ba53d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-28 18:40:03--  https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\n",
            "Resolving archive.ics.uci.edu (archive.ics.uci.edu)... 128.195.10.252\n",
            "Connecting to archive.ics.uci.edu (archive.ics.uci.edu)|128.195.10.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified\n",
            "Saving to: ‘auto-mpg.data.30’\n",
            "\n",
            "auto-mpg.data.30        [ <=>                ]  29.58K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2024-09-28 18:40:04 (242 KB/s) - ‘auto-mpg.data.30’ saved [30286]\n",
            "\n",
            "Epoch 1/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - loss: 612.4639 - val_loss: 568.8234\n",
            "Epoch 2/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 582.8381 - val_loss: 553.4270\n",
            "Epoch 3/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - loss: 582.6166 - val_loss: 535.8313\n",
            "Epoch 4/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 572.4939 - val_loss: 515.3743\n",
            "Epoch 5/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 548.6005 - val_loss: 491.6914\n",
            "Epoch 6/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 495.7661 - val_loss: 464.1836\n",
            "Epoch 7/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - loss: 456.3666 - val_loss: 432.3776\n",
            "Epoch 8/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - loss: 448.2635 - val_loss: 395.7139\n",
            "Epoch 9/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - loss: 411.6976 - val_loss: 354.7966\n",
            "Epoch 10/10\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - loss: 373.2023 - val_loss: 309.6237\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 315.0859 \n",
            "Val loss: 309.6236877441406\n",
            "[[ 58.10728 ]\n",
            " [144.80045 ]\n",
            " [ 99.602554]\n",
            " [136.0188  ]\n",
            " [ 35.871204]\n",
            " [ 66.97012 ]\n",
            " [ 39.69161 ]\n",
            " [ 41.667538]\n",
            " [ 26.520643]\n",
            " [ 50.76717 ]]\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Snippets: Importing libraries",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}